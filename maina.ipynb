{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0dcad97eb31a40c02fdb1764e8f108885f6c3fa2d5ede0b775bbb0ea4b2ba36fa",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 2 - CSS 383 Bioinformatics: Bird Soundscape Analysis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing csv data\n",
    "train_csv = pd.read_csv(\"/Users/tesfashenkute/Downloads/birdsong-recognition/train.csv\")\n",
    "test_csv = pd.read_csv(\"/Users/tesfashenkute/Downloads/birdsong-recognition/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the data\n",
    "train_csv.head\n",
    "test_csv.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrowing down bird species to save on computational power\n",
    "# Narrowing down to aldfly, dowwoo and hamfly\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "\n",
    "for row in range(train_csv.shape[0]) :\n",
    "    for name in ['aldfly','dowwoo', 'hamfly'] :\n",
    "        if train_csv.iloc[row]['ebird_code'] == name :\n",
    "            train_data = train_data.append(train_csv.iloc[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building audio data path\n",
    "main_dir = '/Users/tesfashenkute/Downloads/birdsong-recognition/train_audio'\n",
    "train_data['full_path'] = main_dir + '/' + train_csv['ebird_code'] + '/' + train_data['filename']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting audio data according to bird species code to test for audio corruption\n",
    "aldfly = train_data[train_data['ebird_code'] == \"aldfly\"].sample(1, random_state = 33)['full_path'].values[0]\n",
    "dowwoo = train_data[train_data['ebird_code'] == \"dowwoo\"].sample(1, random_state = 33)['full_path'].values[0]\n",
    "hamfly = train_data[train_data['ebird_code'] == \"hamfly\"].sample(1, random_state = 33)['full_path'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating STFT\n",
    "\n",
    "import json \n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "DATASET_PATH = \"/Users/tesfashenkute/Downloads/birdsong-recognition/train_audio/\"\n",
    "JSON_PATH = \"STFT.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "TO_PROCESS = [\"aldfly\", \"dowwoo\",\"hamfly\"] # Species we want to process (decreases computational time im on a macbook pro lol)\n",
    "\n",
    "# parameters changes because STFTs are much more memory-consuming than MFCCs\n",
    "# This method was found on https://www.kaggle.com/looc60/stft-audio-extraction\n",
    "def save_stft(dataset_path, json_path, n_fft=512, hop_length=2048, segment_duration=4): \n",
    "    \"\"\"Extracts STFTs from music dataset and saves them into a json file along witgh genre labels.\n",
    "\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param json_path (str): Path to json file used to save STFTs\n",
    "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
    "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
    "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    # dictionary to store mapping, labels, and STFTs\n",
    "    data = {\n",
    "        \"mapping\": [], # genres\n",
    "        \"labels\": [], # a number (corresponding to a genres) : targets that we expect\n",
    "        \"stft\": [] # will bbe the inputs\n",
    "    }\n",
    "    \n",
    "    file_count = 0 # keeps teack of the loading process\n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split('/')[-1]\n",
    "            \n",
    "            # Proceed to data extraction only for few species\n",
    "            if semantic_label in TO_PROCESS:\n",
    "                \n",
    "                # Keeps track of loading process\n",
    "                file_count = file_count + 1\n",
    "            \n",
    "                data[\"mapping\"].append(semantic_label)\n",
    "                print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "                # process all audio files in genre sub-dir\n",
    "                \n",
    "                num_file = 0\n",
    "                for f in filenames:\n",
    "                    num_file += 1\n",
    "                    \n",
    "                    # audio file\n",
    "                    file_path = os.path.join(dirpath, f)\n",
    "                    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE) # audio file in array\n",
    "\n",
    "                    audio_duration = librosa.get_duration(signal, sr=SAMPLE_RATE) # different duration for each sample\n",
    "                    num_segments = int(audio_duration // segment_duration) # number of segments the audio can be cut into\n",
    "                    # we want audios of the same duration to allow comparisons\n",
    "\n",
    "                    samples_per_segment = int(SAMPLE_RATE * segment_duration)\n",
    "                    num_stft_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "                    # that will be what we study\n",
    "\n",
    "                    \n",
    "                    # print(\"{}, segment:{}\".format(file_path, d+1), end = '\\r', flush=True)\n",
    "                    print(\"processing file {} on {}, folder {} on {}\".format(num_file,len(filenames),file_count,len(TO_PROCESS)))\n",
    "                    \n",
    "                    # process all segments of audio file\n",
    "                    for d in range(num_segments):\n",
    "\n",
    "                        # calculate start and finish sample for current segment\n",
    "                        start = samples_per_segment * d  # sample at which the segment begin\n",
    "                        finish = start + samples_per_segment # sample at which the segment stops\n",
    "\n",
    "                        # extract stft (what we will use)\n",
    "                        stft = np.abs(librosa.stft(signal[start:finish], \n",
    "                                                    n_fft=n_fft, \n",
    "                                                    hop_length=hop_length))\n",
    "                        stft = librosa.amplitude_to_db(stft, ref = np.max)\n",
    "                        stft = stft.T\n",
    "\n",
    "\n",
    "                        # store only stft feature with expected number of vectors\n",
    "                        if len(stft) == num_stft_vectors_per_segment: \n",
    "                            data[\"stft\"].append(stft.tolist())\n",
    "                            data[\"labels\"].append(i-1)\n",
    "\n",
    "\n",
    "    # save STFTs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent = 4)\n",
    "        print(\"Data successfully saved !\")  \n",
    "\n",
    "# Function execution\n",
    "save_stft(DATASET_PATH, JSON_PATH, segment_duration=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating MFCC\n",
    "\n",
    "import json \n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "DATASET_PATH = \"/Users/tesfashenkute/Downloads/birdsong-recognition/train_audio/\"\n",
    "JSON_PATH = \"MFCC.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "TO_PROCESS = [\"aldfly\", \"dowwoo\",\"hamfly\"] # Species we want to process (decreases computational time)\n",
    "\n",
    "# main function\n",
    "# This method was found on https://www.kaggle.com/looc60/mfcc-audio-extraction\n",
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, segment_duration=6):\n",
    "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
    "\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param json_path (str): Path to json file used to save MFCCs\n",
    "        :param num_mfcc (int): Number of coefficients to extract\n",
    "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
    "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
    "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [], # genres\n",
    "        \"labels\": [], # a number (corresponding to a genres) : targets that we expect\n",
    "        \"mfcc\": [] # will bbe the inputs\n",
    "    }\n",
    "    \n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split('/')[-1]\n",
    "            \n",
    "            # Proceed to data extraction only for few species\n",
    "            if semantic_label in TO_PROCESS:\n",
    "            \n",
    "                data[\"mapping\"].append(semantic_label)\n",
    "                print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "                # process all audio files in genre sub-dir\n",
    "                \n",
    "                num_file = 0\n",
    "                for f in filenames:\n",
    "                    num_file += 1\n",
    "                    \n",
    "                    # audio file\n",
    "                    file_path = os.path.join(dirpath, f)\n",
    "                    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE) # audio file in array\n",
    "\n",
    "                    audio_duration = librosa.get_duration(signal, sr=SAMPLE_RATE) # different duration for each sample\n",
    "                    num_segments = int(audio_duration // segment_duration) # number of segments the audio can be cut into\n",
    "                    # we want audios of the same duration to allow comparisons\n",
    "\n",
    "                    samples_per_segment = int(SAMPLE_RATE * segment_duration)\n",
    "                    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "                    # that will be what we study\n",
    "\n",
    "                    # process all segments of audio file\n",
    "                    for d in range(num_segments):\n",
    "\n",
    "                        # calculate start and finish sample for current segment\n",
    "                        start = samples_per_segment * d  # sample at which the segment begin\n",
    "                        finish = start + samples_per_segment # sample at which the segment stops\n",
    "\n",
    "                        # extract mfcc (what we will use)\n",
    "                        mfcc = librosa.feature.mfcc(signal[start:finish], \n",
    "                                                    sample_rate, \n",
    "                                                    n_mfcc=num_mfcc, \n",
    "                                                    n_fft=n_fft, \n",
    "                                                    hop_length=hop_length)\n",
    "                        mfcc = mfcc.T\n",
    "\n",
    "\n",
    "                        # store only mfcc feature with expected number of vectors\n",
    "                        if len(mfcc) == num_mfcc_vectors_per_segment: \n",
    "                            data[\"mfcc\"].append(mfcc.tolist())\n",
    "                            data[\"labels\"].append(i-1)\n",
    "                            # print(\"{}, segment:{}\".format(file_path, d+1), end = '\\r', flush=True)\n",
    "                            print(\"processing file {} on {}\".format(num_file,len(filenames)), end = '\\r', flush=True)\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent = 4)\n",
    "        print(\"Data successfully saved !\")       \n",
    "\n",
    "# Function execution\n",
    "save_mfcc(DATASET_PATH, JSON_PATH, segment_duration=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow.keras as keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_MFCC = \"MFCC.json\"\n",
    "DATA_PATH_STFT = \"STFT.json\"\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data set from json file\n",
    "\n",
    "def load_data(data_path,data_type):\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(data[data_type])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    print(\"Data loaded.\")\n",
    "    \n",
    "    # Resetting indexes\n",
    "    values = list(set(y))\n",
    "    \n",
    "    for i in range(len(values)):\n",
    "        y[y == values[i]] = i\n",
    "        \n",
    "    # returns the inputs to be split in the following function\n",
    "    return  X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, validation_size):\n",
    "    X, y = load_data(DATA_PATH_MFCC,\"mfcc\")\n",
    "\n",
    "    # splitting test, training and validation data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    # returning test, training and validation split\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_axis(X_train, X_validation, X_test):\n",
    "    # building inputs from new axis\n",
    "\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_validation, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building final data\n",
    "# we will be using MFCC data to train as it is more efficient than STFT\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
    "\n",
    "print(\"Dataset ready for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "# Will attempt using input layer, 3 convolutional layers (all with relu activation function) and an output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will build the CNN model for our training\n",
    "def cnn_build(input_shape, output_shape):\n",
    "    \n",
    "    # initializing network\n",
    "    cnn_model = keras.Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    cnn_model.add(keras.layers.Conv2D(64, (4, 4), activation='relu', input_shape=input_shape))\n",
    "    cnn_model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    cnn_model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # Layer 2\n",
    "    cnn_model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    cnn_model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # Layer 3\n",
    "    cnn_model.add(keras.layers.Conv2D(64, (2, 2), activation='relu', input_shape=input_shape))\n",
    "    cnn_model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    cnn_model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # Inputting into output layer (flattening -> dense)\n",
    "    cnn_model.add(keras.layers.Flatten())\n",
    "    cnn_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    cnn_model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    # Output\n",
    "    cnn_model.add(keras.layers.Dense(output_shape, activation='softmax'))\n",
    "\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting output parameter and labels\n",
    "\n",
    "birds = [\"aldfly\", \"dowwoo\",\"hamfly\"]\n",
    "output_shape = len(birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new axis for CNN inputs\n",
    "X1_train, X1_validation, X1_test = add_axis(X_train, X_validation, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network Training\n",
    "\n",
    "# new input shape\n",
    "input_shape = (X1_train.shape[1], X1_train.shape[2], 1)\n",
    "\n",
    "# Network creation\n",
    "model_conv = cnn_build(input_shape, output_shape)\n",
    "\n",
    "# Network compile on adam optimizer and categorical crossentropy loss function\n",
    "adam_optimizer = keras.optimizers.Adam(learning_rate=0.0001) # Adam optimizer\n",
    "model_conv.compile(optimizer=adam_optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "model_conv.summary()\n",
    "\n",
    "# MODEL TRAINING\n",
    "print(\"\\nTraining:\")\n",
    "history_conv = model_conv.fit(X1_train, y_train, validation_data=(X1_validation, y_validation), batch_size=32, epochs=30)\n",
    "print(\"\\n\")\n",
    "\n",
    "# MODEL EVALUATION (test)\n",
    "test_loss_conv, test_acc_conv = model_conv.evaluate(X_test_new, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Takes in training history of model and outputs graph of train and test accuracy and error rates\n",
    "\n",
    "def plot_model_results(history):\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch Number\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error\")\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in trained model, input data, output and list of birds to generate a confusion matrix\n",
    "\n",
    "def plot_confusion(model, X, y, labels):   \n",
    "    prediction = model.predict(X)\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y, predicted_index, normalize='true')\n",
    "\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(include_values=True,\n",
    "                 cmap='cividis')\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.xaxis.set_ticklabels(labels, fontsize = 10, verticalalignment = 'center')\n",
    "    axes.yaxis.set_ticklabels(labels, fontsize = 10, verticalalignment = 'center', rotation = 90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_results(history_conv)\n",
    "plot_confusion(model_conv, X_test_new, y_test, birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}